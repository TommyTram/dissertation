\chapter{Learning without a model}
\tommy{Deep Q-learning approach}
We want to formulate the problem in such a way that abstracts the information of traffic lights, traffic signs and intention. This way the car is closer to L5 by not relying on the different traffic lights

One motivation example is in how traffic lights works. In Sweden, we have sensors that can sense if there are cars in an intersection and create a traffic light schedule accordingly, compared to the US where the traffic signals set up using timers. As a consequence, Drivers approaching a yellow light 



\section{Approach (State representation, observable and unobservable)}
This paper explored the possibility of solving the problem with \gls{rl} by trying a verity of different methods from the rainbow paper with the addition to the LSTM layer and presented the results that had the highest impact on the conversion. 
\todo{State representation}
This section describes the general state representation used in this research that enables these methods to be generalizable for different type of intersection and crossings. 
By describing the state space as a set of distances to intersection points, we can abstract the map layout of different intersections and the same algorithms would work for intersections variations that we haven't specifically trained on. 
\todo{add image of intersection scenario with 90 degree entry point and 45 degree entry point.}
\todo{Observable states}
Position, velocity and acceleration. 
\todo{Unobservable states}
Intentions. Traffic lights and traffic signs. 
\todo{explain rewards}
large negative reward for invalid actions.
\section{Simulated experiments}
\section{Results and discussion}

LSTM take into account the history, but when applied in the real world with noise the model did not perform as well. 
The immidiate reward for jerk is 
\tommy{finding time to intersection and position itself in a way that does not conflict with other cars.}
