% !TeX spellcheck = <none>
The main focus of this thesis is tactical decision-making for autonomous driving (AD) through intersections with other road users. Human drivers can navigate diverse environments and situations, even those they have never encountered before. Autonomous vehicles are expected to have similar capabilities. This thesis specifically addresses the challenge of navigating intersections where the intentions of other drivers are unknown, as these intentions can be influenced by factors such as driver mood, attention, right-of-way, and traffic signals.

To tackle the complexity of manually specifying reactions for every possible situation, this thesis adopts a learning-based strategy using reinforcement learning (RL). The problem is formulated as a partially observable Markov decision process (POMDP) to account for the uncertainty of unknown driver intentions. A general decision-making agent, based on the deep Q-learning algorithm, is proposed. The contributions of this thesis include the development and application of this method to various simulated intersection scenarios, demonstrating its adaptability and effectiveness in different environments with minimal modifications. By accounting for the inherent uncertainty in driver behavior, this approach enhances the robustness and reliability of the autonomous driving system.

% The main topic for this thesis is tactical decision-making for autonomous driving (AD) through intersections with other road users. Human drivers are able to drive in diverse environments and situations even though they have never driven there before. The same is expected of an autonomous vehicle. Specifically, this thesis study the problem of navigating though an intersection where the intention of other drivers are unknown. These intentions depend on a variety of factors such as the mood or attention of the driver, right of way, traffic signs or lights. By generalizing the future action of the driver to intention, the autonomous vehicle (AV) will be able to handle more complicated scenarios such as a driver running a red light. 
% The large amount of environments and possible scenarios makes it hard to manually specify a reaction for every possible situation.
% Therefore, a learning-based strategy is considered in this thesis, which will introduce different approaches based on reinforcement learning (RL). 

% The problem is formulated as a partially observable Markov decision process (POMDP) to account for the unknown intentions and a general decision-making agent derived from the deep Q learning algorithm is proposed. With few modifications, this method can be applied to different environments, which is demonstrated for various simulated intersection scenarios. 

% Autonomous driving technologies have been developed in the past decades with the objective of increasing safety and efficiency. However, in order to enable such systems to be deployed on a global scale, the problems and concerns regarding safety must be addressed. The difficulty in providing safety guarantees for autonomous driving applications comes from the fact that the self-driving vehicle needs to be able to handle a diverse set of environments and traffic situations. More specifically, it must be able to interact with other road users, whose intentions cannot be perfectly known.

% This thesis proposes a Model Predictive Control~(MPC) approach to ensure safe autonomous driving in uncertain environments. While MPC has been widely used in motion planning and control for autonomous driving applications, the standard literature cannot be directly applied to ensure safety (recursive feasibility) in the presence of other road users, i.e., pedestrians, cyclists, and other vehicles. To that end, this thesis shows how recursive feasibility can still be obtained through a slight modification of the MPC controller design.

% The results of this thesis build upon the assumption that the behavior of the surrounding environment can be predicted to some extent, i.e., a future motion trajectory with some uncertainty bound can be propagated. Then, by postulating the existence of a safe set for the autonomous driving problem, and requiring that the motion prediction models have a consistent structure, safety guarantees can be derived for an MPC controller.

% Finally, this thesis shows that the proposed MPC framework does not only hold in theory and simulations, but that it can also be deployed on a real vehicle test platform and operate in real-time, while still ensuring that the conditions needed for the derived safety guarantees hold.
