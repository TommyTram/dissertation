

% only comma separated full names
\paperauthor{Hannes~Eriksson, Tommy~Tram, Debabrota Basu, Mina Alibeigi, and Christos~Dimitrakakis}

% \paperinfo[short info]{full info}
\paperinfo[\textit{Published in 2024 International Conference on Adaptive Agents and Multi-Agent Systems~(AAMAS)}]{
    \textit{Published in 2024 International Conference on Adaptive Agents and Multi-Agent Systems~(AAMAS)},\\
	pp. 516--524, May. 2024.
}

% \papertitle[short title]{full title}
\papertitle[Reinforcement Learning in the Wild with Maximum Likelihood-based Model Transfer]{Reinforcement Learning in the Wild with Maximum Likelihood-based Model Transfer}

% if you want to use an auto-generated paper summary, please fill in the variable \papersummary{}.
\papersummary{
For decision-problems with insufficient data, it is imperative to take into account not only what you know but also what you do not know. In this work, ways of transferring knowledge from known, existing tasks to a new setting is studied. In particular, for tasks such as autonomous driving, the optimal controller is conditional on things such as, the physical properties of the vehicle, the local and regional traffic rules and regulations and also on the specific scenario trying to be solved. Having separate controllers for every combination of these conditions is intractable. By assuming problems with similar structure, we are able to leverage knowledge attained from similar tasks to guide learning for new tasks. We introduce a maximum likelihood estimation procedure for solving Transfer Reinforcement Learning (TRL) of different types. This procedure is then evaluated over a set of autonomous driving settings, each of which constitutes an interesting scenario for autonomous driving agents to make use of external information. We prove asymptotic regret bounds for proposed method for general structured probability matrices in a specific setting of interest.\\\indent
The thesis author contributed with the problem formulation and experimental analysis of the paper.}
